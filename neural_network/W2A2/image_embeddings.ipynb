{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_tuner\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the datasets\n",
    "\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    #train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    #test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes=load_dataset()\n",
    "x_train=train_set_x_orig\n",
    "y_train=train_set_y_orig.reshape(-1,1)\n",
    "x_test=test_set_x_orig\n",
    "y_test=test_set_y_orig.reshape(-1,1)\n",
    "\n",
    "batch_size=32\n",
    "dataset=tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(batch_size)\n",
    "eval_dataset=tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_model(input_shape:tuple=(64,64,3)):\n",
    "    '''\n",
    "    Define the deep learning model with 2 hidden layers\n",
    "    '''\n",
    "    inputs=tf.keras.Input(shape=input_shape)\n",
    "    x=tf.keras.layers.Rescaling(1.0/255)(inputs)\n",
    "    x=tf.keras.layers.Flatten()(x)\n",
    "    x=tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x=tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    outputs=tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model=tf.keras.Model(inputs, outputs)\n",
    "    model.summary()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " rescaling_10 (Rescaling)    (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 12288)             0         \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 128)               1572992   \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,589,633\n",
      "Trainable params: 1,589,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "strategy=tf.distribute.MirroredStrategy()\n",
    "with strategy.scope():\n",
    "    model=define_model()\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=100\n",
    "batch_size=32\n",
    "\n",
    "callbacks=[tf.keras.callbacks.ModelCheckpoint(filepath='outputs/model_{epoch}', save_freq='epoch'), tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")]\n",
    "#history=model.fit(dataset, epochs=epochs, validation_data=eval_dataset, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 12ms/step - loss: 3.5653 - accuracy: 0.6800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.5653438568115234, 0.6800000071525574]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=model.evaluate(eval_dataset)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(eval_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(9,5))\n",
    "\n",
    "num_obs=predictions.shape[0]\n",
    "x=np.arange(num_obs)\n",
    "\n",
    "plt.scatter(x, predictions)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define, train, evaluate a deep learning model for image classification\n",
    "\n",
    "def get_model(input_shape:tuple=(64,64,3)):\n",
    "    ''' \n",
    "    Define a deap learning model\n",
    "    '''\n",
    "    inputs=tf.keras.Input(shape=input_shape)\n",
    "    x=tf.keras.layers.Rescaling(1.0/255)(inputs)\n",
    "    x=tf.keras.layers.Flatten()(x)\n",
    "    x=tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x=tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x=tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    x=tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "    x=tf.keras.layers.Dense(8, activation='relu')(x)\n",
    "    outputs=tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "    model=tf.keras.Model(inputs, outputs)\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_18 (InputLayer)       [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " rescaling_16 (Rescaling)    (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 12288)             0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 128)               1572992   \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,584,001\n",
      "Trainable params: 1,584,001\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.8577 - accuracy: 0.5502\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6593 - accuracy: 0.6555\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6671 - accuracy: 0.6507\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6612 - accuracy: 0.6555\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6562 - accuracy: 0.6555\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.6555\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6484 - accuracy: 0.6555\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6481 - accuracy: 0.6555\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6469 - accuracy: 0.6555\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6454 - accuracy: 0.6555\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6432 - accuracy: 0.6555\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6408 - accuracy: 0.6555\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6383 - accuracy: 0.6555\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.6555\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6306 - accuracy: 0.6555\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.6246 - accuracy: 0.6555\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6196 - accuracy: 0.6555\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6118 - accuracy: 0.6555\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6029 - accuracy: 0.6555\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5924 - accuracy: 0.6555\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5795 - accuracy: 0.6555\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5740 - accuracy: 0.6555\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.6555\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5313 - accuracy: 0.6651\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.6794\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.6842\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.6842\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.7177\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4716 - accuracy: 0.6842\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8038\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.7751\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.7703\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7177\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5827 - accuracy: 0.7560\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4510 - accuracy: 0.7990\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7225\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.7464\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4208 - accuracy: 0.6842\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.7081\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8230\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3012 - accuracy: 0.8373\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.7751\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4565 - accuracy: 0.8038\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.7656\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3711 - accuracy: 0.7608\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.7847\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2767 - accuracy: 0.8995\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2876 - accuracy: 0.8947\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2955 - accuracy: 0.7656\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3532 - accuracy: 0.7512\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2496 - accuracy: 0.8373\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2131 - accuracy: 0.8660\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3927 - accuracy: 0.7464\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.8278\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.8517\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.6280 - accuracy: 0.7703\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5608 - accuracy: 0.8038\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5005 - accuracy: 0.7990\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4162 - accuracy: 0.8134\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.4134 - accuracy: 0.8038\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3600 - accuracy: 0.8134\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2901 - accuracy: 0.8278\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2422 - accuracy: 0.8995\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2396 - accuracy: 0.8900\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2363 - accuracy: 0.8852\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1920 - accuracy: 0.9187\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1435 - accuracy: 0.9522\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9569\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1286 - accuracy: 0.9426\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1624 - accuracy: 0.9234\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1727 - accuracy: 0.9378\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1139 - accuracy: 0.9665\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1072 - accuracy: 0.9569\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.9569\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0671 - accuracy: 0.9809\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0463 - accuracy: 0.9904\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0613 - accuracy: 0.9761\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0761 - accuracy: 0.9617\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.1196 - accuracy: 0.9617\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1515 - accuracy: 0.9139\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1565 - accuracy: 0.9234\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9809\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1285 - accuracy: 0.9474\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9474\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0327 - accuracy: 0.9952\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0235 - accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0211 - accuracy: 0.9952\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0226 - accuracy: 0.9952\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0057 - accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9952\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9952\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9904\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0161 - accuracy: 0.9952\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0175 - accuracy: 0.9904\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0217 - accuracy: 0.9952\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.8756\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.5564 - accuracy: 0.8230\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.2911 - accuracy: 0.8565\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1381 - accuracy: 0.9665\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.1094 - accuracy: 0.9761\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0646 - accuracy: 0.9761\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0266 - accuracy: 0.9904\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0172 - accuracy: 0.9952\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0053 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0026 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 9.1252e-04 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 7.5081e-04 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 6.3352e-04 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.8374e-04 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.6773e-04 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.1936e-04 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.8582e-04 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.6705e-04 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.4013e-04 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.2080e-04 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 4.0052e-04 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.8312e-04 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.6624e-04 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.2776e-04 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.1264e-04 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 2.7748e-04 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 2.5000e-04 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 2.3184e-04 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0445e-04 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.8205e-04 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.6650e-04 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.5441e-04 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.4438e-04 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.3517e-04 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.2671e-04 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.1892e-04 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.1191e-04 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.0562e-04 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 9.9679e-05 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 9.4769e-05 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 8.9476e-05 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 8.4664e-05 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 8.0457e-05 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 7.6569e-05 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 7.2912e-05 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.9537e-05 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.6475e-05 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 6.3707e-05 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.9229e-05 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.5263e-05 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.1894e-05 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.9092e-05 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.6505e-05 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.4204e-05 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.2264e-05 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 4.0556e-05 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.8944e-05 - accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.7516e-05 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.6211e-05 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.5024e-05 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.3891e-05 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.2831e-05 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.1835e-05 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 3.0917e-05 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 3.0041e-05 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.9232e-05 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.8442e-05 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.7676e-05 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.6897e-05 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.6140e-05 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.5423e-05 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.4724e-05 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.4086e-05 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.3442e-05 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.2820e-05 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.2228e-05 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1630e-05 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.1055e-05 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 2.0501e-05 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.9958e-05 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.9452e-05 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.8967e-05 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8495e-05 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.8022e-05 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7582e-05 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.7163e-05 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.6759e-05 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.6381e-05 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 1.6012e-05 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.5646e-05 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.5285e-05 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4943e-05 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4623e-05 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.4301e-05 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14dddb3d0>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs=200\n",
    "model.fit(dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 3.1273 - accuracy: 0.8200\n"
     ]
    }
   ],
   "source": [
    "results=model.evaluate(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_obs=predictions.shape[0]\n",
    "plt.scatter(np.arange(num_obs), predictions)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    ''' \n",
    "    Generate a compile deep learning model\n",
    "    '''\n",
    "    inputs=tf.keras.Input(shape=(64,64,3))\n",
    "    x=tf.keras.layers.Rescaling(1.0/255)(inputs)\n",
    "    x=tf.keras.layers.Flatten()(x)\n",
    "    for i in range(4):\n",
    "        x=tf.keras.layers.Dense(units=hp.Int('units'+str(i), min_value=32, max_value=256, step=32), activation='relu')(x)\n",
    "    outputs=tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model=tf.keras.Model(inputs, outputs)\n",
    "    adam=tf.keras.optimizers.legacy.Adam(hp.Choice('learning_rate', values=[1e-1,1e-2,1e-3,1e-4]))\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=100,\n",
    "    max_retries_per_trial=2,\n",
    "    directory='outputs/hp_tuner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 100 Complete [00h 00m 00s]\n",
      "val_loss: 0.9510513544082642\n",
      "\n",
      "Best val_loss So Far: 0.6722689867019653\n",
      "Total elapsed time: 00h 00m 49s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(dataset, validation_data=eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in outputs/hp_tuner/untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 014 summary\n",
      "Hyperparameters:\n",
      "units0: 128\n",
      "units1: 64\n",
      "units2: 96\n",
      "units3: 32\n",
      "learning_rate: 0.0001\n",
      "Score: 0.6722689867019653\n",
      "\n",
      "Trial 061 summary\n",
      "Hyperparameters:\n",
      "units0: 32\n",
      "units1: 256\n",
      "units2: 32\n",
      "units3: 96\n",
      "learning_rate: 0.1\n",
      "Score: 0.6812006235122681\n",
      "\n",
      "Trial 058 summary\n",
      "Hyperparameters:\n",
      "units0: 64\n",
      "units1: 160\n",
      "units2: 224\n",
      "units3: 32\n",
      "learning_rate: 0.001\n",
      "Score: 0.6864553689956665\n",
      "\n",
      "Trial 019 summary\n",
      "Hyperparameters:\n",
      "units0: 32\n",
      "units1: 224\n",
      "units2: 192\n",
      "units3: 64\n",
      "learning_rate: 0.01\n",
      "Score: 0.695160448551178\n",
      "\n",
      "Trial 037 summary\n",
      "Hyperparameters:\n",
      "units0: 224\n",
      "units1: 160\n",
      "units2: 128\n",
      "units3: 96\n",
      "learning_rate: 0.1\n",
      "Score: 0.6976955533027649\n",
      "\n",
      "Trial 073 summary\n",
      "Hyperparameters:\n",
      "units0: 192\n",
      "units1: 160\n",
      "units2: 96\n",
      "units3: 96\n",
      "learning_rate: 0.0001\n",
      "Score: 0.704602062702179\n",
      "\n",
      "Trial 068 summary\n",
      "Hyperparameters:\n",
      "units0: 128\n",
      "units1: 256\n",
      "units2: 256\n",
      "units3: 32\n",
      "learning_rate: 0.001\n",
      "Score: 0.7059629559516907\n",
      "\n",
      "Trial 082 summary\n",
      "Hyperparameters:\n",
      "units0: 224\n",
      "units1: 160\n",
      "units2: 32\n",
      "units3: 32\n",
      "learning_rate: 0.0001\n",
      "Score: 0.7069863677024841\n",
      "\n",
      "Trial 066 summary\n",
      "Hyperparameters:\n",
      "units0: 64\n",
      "units1: 32\n",
      "units2: 64\n",
      "units3: 128\n",
      "learning_rate: 0.1\n",
      "Score: 0.7114588022232056\n",
      "\n",
      "Trial 063 summary\n",
      "Hyperparameters:\n",
      "units0: 256\n",
      "units1: 96\n",
      "units2: 96\n",
      "units3: 224\n",
      "learning_rate: 0.0001\n",
      "Score: 0.718858003616333\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step - loss: 0.6723 - accuracy: 0.6000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6722689867019653, 0.6000000238418579]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = tuner.get_best_models()[0]\n",
    "evals=best_model.evaluate(eval_dataset)\n",
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    ''' \n",
    "    Generate a compile deep learning model\n",
    "    '''\n",
    "    inputs=tf.keras.Input(shape=(64,64,3))\n",
    "    x=tf.keras.layers.Rescaling(1.0/255)(inputs)\n",
    "    x=tf.keras.layers.Flatten()(x)\n",
    "    x=tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    x=tf.keras.layers.Dense(128, activation='relu')(x)\n",
    "    x=tf.keras.layers.Dense(64, activation='relu')(x)\n",
    "    x=tf.keras.layers.Dense(32, activation='relu')(x)\n",
    "    x=tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "    x=tf.keras.layers.Dense(8, activation='relu')(x)\n",
    "    outputs=tf.keras.layers.Dense(1, activation='sigmoid')(x)\n",
    "    model=tf.keras.Model(inputs, outputs)\n",
    "    adam=tf.keras.optimizers.legacy.Adam(hp.Choice('learning_rate', values=[1e-1,1e-2,1e-3,1e-4, 1e-5]))\n",
    "    model.compile(optimizer=adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from outputs/hp_tuner/untitled_project/tuner0.json\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=200,\n",
    "    max_retries_per_trial=2,\n",
    "    directory='outputs/hp_tuner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 200 Complete [00h 00m 01s]\n",
      "val_loss: 1.2917261123657227\n",
      "\n",
      "Best val_loss So Far: 0.6545006632804871\n",
      "Total elapsed time: 00h 01m 04s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner.search(dataset, validation_data=eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in outputs/hp_tuner/untitled_project\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_loss\", direction=\"min\")\n",
      "\n",
      "Trial 158 summary\n",
      "Hyperparameters:\n",
      "units0: 32\n",
      "units1: 32\n",
      "units2: 64\n",
      "units3: 160\n",
      "learning_rate: 0.1\n",
      "Score: 0.6545006632804871\n",
      "\n",
      "Trial 173 summary\n",
      "Hyperparameters:\n",
      "units0: 192\n",
      "units1: 32\n",
      "units2: 192\n",
      "units3: 224\n",
      "learning_rate: 0.001\n",
      "Score: 0.659095287322998\n",
      "\n",
      "Trial 192 summary\n",
      "Hyperparameters:\n",
      "units0: 192\n",
      "units1: 64\n",
      "units2: 160\n",
      "units3: 160\n",
      "learning_rate: 0.1\n",
      "Score: 0.6601036190986633\n",
      "\n",
      "Trial 112 summary\n",
      "Hyperparameters:\n",
      "units0: 32\n",
      "units1: 160\n",
      "units2: 64\n",
      "units3: 256\n",
      "learning_rate: 0.1\n",
      "Score: 0.6629336476325989\n",
      "\n",
      "Trial 185 summary\n",
      "Hyperparameters:\n",
      "units0: 64\n",
      "units1: 192\n",
      "units2: 96\n",
      "units3: 64\n",
      "learning_rate: 0.1\n",
      "Score: 0.665473461151123\n",
      "\n",
      "Trial 168 summary\n",
      "Hyperparameters:\n",
      "units0: 64\n",
      "units1: 192\n",
      "units2: 256\n",
      "units3: 32\n",
      "learning_rate: 0.1\n",
      "Score: 0.6678012609481812\n",
      "\n",
      "Trial 014 summary\n",
      "Hyperparameters:\n",
      "units0: 128\n",
      "units1: 64\n",
      "units2: 96\n",
      "units3: 32\n",
      "learning_rate: 0.0001\n",
      "Score: 0.6722689867019653\n",
      "\n",
      "Trial 166 summary\n",
      "Hyperparameters:\n",
      "units0: 192\n",
      "units1: 64\n",
      "units2: 256\n",
      "units3: 224\n",
      "learning_rate: 0.0001\n",
      "Score: 0.6790984272956848\n",
      "\n",
      "Trial 061 summary\n",
      "Hyperparameters:\n",
      "units0: 32\n",
      "units1: 256\n",
      "units2: 32\n",
      "units3: 96\n",
      "learning_rate: 0.1\n",
      "Score: 0.6812006235122681\n",
      "\n",
      "Trial 109 summary\n",
      "Hyperparameters:\n",
      "units0: 160\n",
      "units1: 192\n",
      "units2: 128\n",
      "units3: 128\n",
      "learning_rate: 0.1\n",
      "Score: 0.6845845580101013\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 4ms/step - loss: 0.6545 - accuracy: 0.6600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6545006632804871, 0.6600000262260437]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model=tuner.get_best_models()[0]\n",
    "\n",
    "evals=best_model.evaluate(eval_dataset)\n",
    "evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
